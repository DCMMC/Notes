\chapter{Recommentation System}\label{sec:rs}

\chapternote{Sequence-based Recommentation System}{Intern @ Tencent}

\begin{learningobjectives}
	\item Recommentation System
	\item Contrastive Learning
	\item Sequence Modeling
	\item Graph Neural Network
\end{learningobjectives}

\dependencies{NLP Basic}

\section{Recommender Systems}

Stages:

\begin{itemize}
	\item \textbf{Matching}: Generates hundreds of candidate items from the extremely large item pool (million-level or even billion-level). Usually contains multiple matching channels with multiple (lightweight) models, such as embedding matching, geographical matching, popularity matching, social matching, etc.
	\item \textbf{Ranking}: Candidate items merged from different channels are scored by a single ranking model.
	\item \textbf{Re-ranking}: To meet the requirements of freshness, diversity, fairness, etc, a re-ranking stage removes certain items or changes the order of the list of items.
\end{itemize}

Scenarios:

\begin{itemize}
	\item \textbf{Social Recommendation}: \emph{social influence}: users’ behavior (e.g., like) may be influenced by what their friends might do or think. \emph{social homophily}: people tend to build social relations with others who have similar preferences with them.
	\item \textbf{Sequential Recommendation}: Users will produce a large number of interaction behaviors over time (i.e., historical behaviors). The goal is to predict the next item the user will interact, w.r.t. historical behaviors.
	\item \textbf{Session-based Recommendation}: It is impossible or not necessary to track the user’s behaviors over a long period of time due to limited storage resources. Session-based recommendation aims to predicting the next item with a given behavioral session data.
	\item \textbf{Bundle Recommendation}: Bundle recommendation aims to recommend a combination of items (e.g., music playlists) for users instead of independent items.
	\item \textbf{Cross-Domain Recommendation}: Utilize information from multiple domains can improve performance.
	\item \textbf{Multi-behavior Recommendation}: Users may interact with multiple types of behaviors (e.g., user clicks on the video may also collect or comment).
\end{itemize}

Objectives:

\begin{itemize}
	\item \textbf{Diversity}: individual-level (the dissimilarity of the recommended items for certain user) and system-level diversity (dissimilarity of recommendation results of different users).
	\item \textbf{Explainability}: Current representing explainable information requires graph-structural item attributes with the power of GNN.
	\item \textbf{Fairness}: user fairness and item faireness.
\end{itemize}

\subsection{Sequential Recommendation}

Challenges~\mycite{SURGE}:

\begin{enumerate}
	\item User behaviors in long sequences contain implicit (e.g., clicks and watches compared with explicit such as likes and favorities) and noisy (user may click on items that are not of their interest most of the time and will not choose similar items for interaction afterward) preference signals.
	\item User behaviors are always drifting over the time due to their diversity.
\end{enumerate}

\section{Contrastive Self-supervised Learning}

\concept{Self-supervised Learning}: a learning paradigm which aims to capture the intrinsic patterns and properties of input
data without using human-provided labels. For example, the two objectives of BERT.

\concept{Contrastive Self-supervised Learning}: generate (large number of) augmented examples of original data examples, create a task to predict whether two augmented examples come from the same original data example or not.
In CV, the augmentation includes cropping, flipping, distortion and rotation.
In NLP, it includes word deletion, reordering, and substitution.

SimCLR~\mycite{SimCLR}: $\boldsymbol{z}$ is a latent representation of the input image $\boldsymbol{x}$. Given a similar pair $(\boldsymbol{x}_i, \boldsymbol{x}_j)$, and a set of negative images $\boldsymbol{x}_k$ that dissimilar from the original image of $\boldsymbol{x}_i$, the contrastive loss is:

\begin{equation} \label{eq:simclr}
	- \log \frac{\exp(\text{sim}(\boldsymbol{z}_i, \boldsymbol{z}_j)/\tau)}{\exp(\text{sim}(\boldsymbol{z}_i, \boldsymbol{z}_j)/\tau) + \sum_k \exp(\text{sim}(\boldsymbol{z}_i, \boldsymbol{z}_k)/\tau)}
\end{equation}
where $\tau$ is a temperature parameter.

But SimCLR requires a large minibatch size to yield high performance.
MoCo (Momentum Contrast)~\mycite{MoCo} addresses this problem w/ the hypothesis that good features can be learned by a \emph{large} dictionary (by a queue) that covers a rich set of negative samples, while the encoder for the dictionary keys is kept as \emph{consistent} as possible (by momentum update) despite its evolution.
The queue contains many mini-batches.
In each step, the current mini-batch is enqueued to the dictionary queue, and the oldest mini-batch in the queue is removed.
To avoid rapidly changing encoder that reduces the key (i.e., the second parameter of $\text{sim}(\cdot, \cdot)$ in Eq.~\ref{eq:simclr}, and the first parameter is query) representations’ consistency.
The authors propose a momentum update ($\theta_k \leftarrow m\theta_k + (1 - m) \theta_q$ where $m$ is a large momentum coefficient, e.g., $0.99$, $\theta_q$ is parameters of the representation model of the query) to address this issue.
MoCo uses \emph{dual-encoder} architecture, i.e., a encoder $f_q$ for the query, and another encoder $f_k$ for keys.

CERT (Contrastive Self-supervised Learning for Language Understanding)~\mycite{fang2020cert} utilizes MoCo to fine-tune (aka., secondary pre-train) pre-trained BERT (or any other pre-training models).
The augmentation approach is \emph{back-translation}: given sentence $x$ of source language $S$, translate $x$ to $y$ in language $T$, and then translate $y$ back to augmented sample $x^\prime$ in language $S$.
With different $T$ and different translation model, we can collect many augmented samples.
However, the results of CERT are not significant and worse than ALBERT.

\begin{figure}[!thp]
	\centerline{\includegraphics[width=10.0cm]{figs/SimCSE.png}}
	\caption{General idea of SimCSE.}
	\label{fig:SimCSE}
\end{figure}

SimCSE~\mycite{gao2021simcse} (Simple Contrastive Learning of Sentence Embeddings) leverages the dropout mask (like in BERT) to achieve the positve sample pairs, and proposes a supervised SimCSE w/ a natural language inference (NLI) datasets.
In the dataset, each sentence (aka., query) contains one entailment and one contradication.
The entailment is the positive sample (aka., key), the contradiction is the negative sample (key).
According to Want et al.~\mycite{wang2020hypersphere}, the quality of contrastive learning can be measured by alignment (the distance of the latent representations of the positive pair should close) and uniformity (the distance of the query and all the negative keys should scatter uniformly on the hypersphere).
It's shown~\mycite{wang2020hypersphere} that the anisotropy problem appears in language representations.
The number of (dominating and significant) singular values of the word embedding matrix in a language model decay drastically.
This is unfavorable to the uniformity.

ELECTRA~\mycite{clark2020electra} utilizes a GAN-style training process to learn a more powerful LM.
It uses MLM (masked language modeling, e.g., BERT) as the generator.
The output of the generator replaces the masked tokens with the predicted ones.
The discriminator is also a transformer encoder, whose \emph{replaced token detection} task is to predict whether each token in the output of generator is replaced by the generator or not.
The discriminator is the final pre-trained LM and the generator is a auxiliary network.
Compared with MLM-based methods, ELECTRA substantially outperforms them with less computations.
COCO-LM~\mycite{meng2021cocolm} enhances the replaced token detection of ELECTRA with CLM (Correcting Language Modeling).
The CLM is with a multi-task setting that combines the copy mechanism (aka., replaced token detection) and (a harder task) correction of the replaced tokens.
Pretraining at token level does not explicitly learn language semantics at the sequence level.
In addition to the token level pretraining, COCO-LM also introduces a sequence contrastive learning task (SCL).
The SCL is just a vanilla contractive learning where the query is the original sequence and the positive key is the randomly cropping of the query.
The output of \texttt{[CLS]} token is used as the representation of the whole sequence.

DeCLUTR~\mycite{DeCLUTR} proposes a token-level contrastive learning task based on span sampling.
The anchor is a randomly sampled span in a document.
For each anchor, there are multiple positive spans sampled near by the anchor.
The length of the anchor is longer than it's positives.
In most cases, the positive span is overlapped or subsumed with the anchor.
The negative spans inlcude easy (sampled from other documents) and hard negatives (sampled from the same document of the anchor).
A pooler (aka., mean pooling) maps the encodings of the tokens in the sample into a fixed-length encoding.
The performance of the mean pooling outperforms the embedding of \texttt{[CLS]} token.


\subsection{Relation to Metric Learning}

Metric learning is a type of representation learning that aims to learn an embedding space where the vector representations of similar data are mapped close together, and vice versa.
As a most successful approach of deep metric learning, contrastive learning attempts to close the distance between the anchor (aka., query) data point and some corresponding positive data points.
Under the setting of metric learning, MLM can be seen as an instance of contrastive learning.

\section{Graph Neural Networks}

Types:

\begin{itemize}
	\item \textbf{Homogeneous graph}: only one type of nodes and edges.
	\item \textbf{Heterogeneous graph}: there are multiple types of nodes or edges.
	\item \textbf{Hypergraph}: degree of the edge may large than two.
\end{itemize}

GNN:

\begin{itemize}
	\item GCN
	\item GraphSAGE
	\item GAT
	\item HetGNN
	\item HGNN
\end{itemize}

Model Optimization:

\begin{itemize}
	\item 
\end{itemize}

SURGE~\mycite{SURGE} proposes a novel GNN architecture to approach sequential recommendation by taking into consideration the implicit and noisy signal behaviors and fast-changing preferences.
According to the prior assumption that neighbor nodes are similar, and dense subgraphs are the core interests of users.
The authors construct graph with metric learning.
Given two item (node) embeddings $h_i, h_j$, the multi-head similarity metric function is:

\begin{align}
	M_{ij}^\delta &= \cos(w_\delta \odot h_i, w_\delta \odot h_j), \\
	M_{ij} &= \frac{1}{\phi} \sum_{\delta = 1}^\phi M_{ij}^\delta
\end{align}
where each head can be seen as one perspective and each element in weight vector $w_\delta$ is used to adaptively highlight different dimensions of the item embeddings.

Constructing graph from the similarity matrix $M$ w/ $\epsilon$-sparseness:

\begin{equation}
	A_{ij} = \begin{cases}
		1, & M_{ij} \ge \text{Rank}_{\epsilon n^2} (M); \\
		0, & \text{otherwise};
	\end{cases}
\end{equation}
where $A$ is the adjacency matrix of the generated graph and $\text{Rank}_{\epsilon n^2}(\cdot)$ returns the value of $\epsilon n^2$-th largest value.

To gather weak (implicit) signals to strong (explicit) ones that accurately reflect user perferences, the information in the graph is aggregated (interest fusion) via cluster- and query (current target prediction item)-aware graph attentive convolution:

\begin{equation}
	h_i^\prime = \parallel_{\delta = 1}^\phi \sigma (W_a^\delta \cdot \text{Agg}(E_{ij}^\delta \cdot h_j | j \in \mathcal{N}(i)) + h_i)
\end{equation}
where $\text{Agg}(\cdot)$ is the aggregation function such as mean, sum, etc, $E_{ij}^\delta$ are normalized attention coefficients obtained by the $\delta$-th attention head, $W_a^\delta$ is a linear transformation, and $\parallel$ denotes the concatenation operation.

The cluster- and query-aware attention $E_{ij}$ (for one head) is given by:

\begin{align}
	\alpha_i &= \text{Att}_c (W_c h_i \vert h_{i_c} \vert W_c h_i \odot h_{i_c}), \\
	\beta_j &= \text{Att}_q (W_q h_j \vert h_t \vert W_q h_j \odot h_t), \\
	E_{ij} &= \text{softmax}_j (\alpha_i + \beta_j) = \frac{\exp (\alpha_i + \beta_j)}{\sum_{k \in \mathcal{N}_i} (\exp (\alpha_i + \beta_k))}
\end{align}
where $h_{i_c}$ is the average value of all nodes' embedding in the cluster ($k$-hop neighborhood) of the node $h_i$, $\text{Att}$ is a two-layer MLP w/ LeakyReLU, $h_t$ is the target (query) item embedding (\textit{viz.} learn the user interest's independent evolution for different target intertests), and $E_{ij}$ is the additive attention to consider the factors of cluster and query simultaneously.

Graph pooling is applied to fuse (aka. evolution) implicit interest signals to explicit ones.

\begin{align}
	S_{i,:} &= \text{softmax} (W_p \cdot \text{Agg} (A_{ij}) \cdot h_j^\prime | j \in \mathcal{N}_i), \\
	[h_1^*, \cdots, h_m^*] &= S^\top [h_1^\prime, \cdots, h_n^\prime]^\top, \\
	[\gamma_1^*, \cdots, \gamma_m^*] &= S^\top [\gamma_1^\prime, \cdots, \gamma_n^\prime]^\top, \\
	\gamma_i &= \text{softmax}_i (\beta_i), \\
	A^* &= S^\top A S
\end{align}
where $S \in \mathbb{R}^{n \times m}$ is a soft cluster assignment matrix.

However, it is difficult to train $S$ and the temporal order of the nodes $h_i$ and the pooled nodes $h_i^*$ reflect the historical user interest.
The authors use some trivial regularization terms to alleviate the issue.

\begin{align}
	L_M = \lVert A - SS^\top \rVert_F, \quad &\parbox{15em}{ make two nodes with greater connection strength map to the same cluster}, \\
	L_A = \frac{1}{n} \sum_{i=1}^n H(S_{i,:}), \quad &\parbox{15em}{ approach rach row a one-hot vector}, \\
	L_P = \lVert p_n S - p_m \rVert_2, \quad &\parbox{15em}{ make the position of the non-zero elements in S closer to the main diagonal elements}
\end{align}
where position encoding vectors $p_n = [1, 2, \cdots, n], p_m = [1, 2, \cdots, m]$.

Graph readout to aggregates all node embeddings of the raw graph (before pooling):

\begin{align}
	h_g = \text{Readout} ([\gamma_i \cdot h^\prime_i | i \in \mathcal{G}])
\end{align}
where $\text{Readout}(\cdot)$ is just the sum in the paper to ensure permutation invariant.

Any sequential recommendation method can be used to model the pooled sequence $h^*$, where this paper uses $h_s = \text{AUGRU}(h_1^*, \cdots, h_m^*)$.
The final prediction is:

\begin{equation}
	\hat{y} = \text{Pred} (h_s \vert h_g \vert h_t \vert h_g \odot h_t)
\end{equation}
where Pred is a two-layer MLP.

The task is CTR (CTR).
The loss is vanilla NLL (negative log-likelihood) w/ L2 regularization term.